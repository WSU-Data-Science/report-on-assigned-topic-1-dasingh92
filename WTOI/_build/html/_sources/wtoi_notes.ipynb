{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wave theory of information\n",
    "\n",
    "Our sensing ability to capture the distinction between two different waveforms dictates the limits of the amount of information transferred by a propagating wave. The problem of quantifying this precisely requires a mathematical description and a physical understanding of both propagation and the communication processes [Massimo Franceschetti, 2018]. The focus in these notes will be on propagation of electromagnetic waves based on Maxwell's theory of electromagnetism, and on communication as described by Shannon's Law.\n",
    "\n",
    "The central theme of [Massimo Franceschetti, 2018] is that Shannon's information-theoretic limits are natural. They are revealed by observing physical quantities at certain asymptotic scales where finite dimenionality emerges and observational uncertainties are averaged out. These limits are rigorous, and obey the mathematical rules that govern the model of reality on which the the physical theories are based.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shannon's Law\n",
    "\n",
    "Information theory describes in the language of mathematics the limits for the communication of information. These limits are operational, of real engineering significance, and independent of the semantic aspects associated with communication process [Massimo Franceschetti, 2018]. They arise from the following set of constraints expressing our inability to appreciate the infinitum:\n",
    "\n",
    "- Finite energy : Communication occurs by finite expenditure of energy.\n",
    "- Finite dimensionality : Communication occurs by selecting among a range of possible choices, each identified by a finite number of attributes.\n",
    "- Finite resolution : Each attribute can be observed with limited precision.\n",
    "\n",
    "According to Shannon, reliable communication can occur if probability of miscommunication tends to zero within appropriate limiting regimes. In these regimes, some interesting physical phenomena take place such as the following:\n",
    "\n",
    "*  The space-time fields used to convey information become amenable to a discrete representation, and the finite dimensionality of the physical world is revealed. This allows us to view information-theoretic results as being imposed by laws of nature.\n",
    "*  Classically information theory considers time asymptotics, used to describe point-to-point communication.\n",
    "* Their natural counterparts, spatial asymptotics are used to extend the description to communication between multiple transmitters and receivers, and to the remote sensing world around us.\n",
    "\n",
    "A key measure in information theory is entropy. Entropy quantifies the amount of uncertainty involved in the value of a random variable or the outcome of a random process. For example, identifying the outcome of a fair coin flip (with two equally likely outcomes) provides less information (lower entropy) than specifying the outcome from a roll of a die (with six equally likely outcomes). Some other important measures in information theory are mutual information, channel capacity, error exponents, and relative entropy. Important sub-fields of information theory include source coding, algorithmic complexity theory, algorithmic information theory, and information-theoretic security."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concentration Behaviors\n",
    "\n",
    "Basis of the asymptotic arguments that lead to the information-theoretic limits is the consept of *concentration*.\n",
    "\n",
    "Let us consider a space-time waveform $f(x,y,z,t)$ of finite energy, transmitted for $T$ seconds. As $T \\to \\infty$, we can define the effective frequency bandwidth of the waveform as the effective spectral support in the Fourier-transformed angular frequency domain (for more information check out this link to [spectral concentration in wave theory](https://en.wikipedia.org/wiki/Spectral_concentration_problem ) ). So as the time domain support is increased, the signal when viewed in frequency domain can be more and more concentrated inside the bandwidth. Due to this phenomenon EM signals with large $T$ can be considered as occupying a finite bandwidth. \n",
    "\n",
    "Signals with finite energy and bandwidth have another mathematical property, i.e., they exhibit a limit on the amount of variation they can undergo in any given time interval, and therefore when observed at a finite resolution, on the amount of information they can carry over time. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (WSU)",
   "language": "python",
   "name": "wsu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
